{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7030431-add5-4f25-9c16-36d3685e27a2",
   "metadata": {},
   "source": [
    "## Sentiment Analysis for Brand Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e6d90-10f3-4136-85e8-d711b09e307f",
   "metadata": {},
   "source": [
    "### Introduction to VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132ef21-a786-46fd-a9a1-badbb4f879fa",
   "metadata": {},
   "source": [
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool designed for analyzing sentiment in text data. Developed by C.J. Hutto and Eric Gilbert, VADER is widely used for sentiment analysis tasks due to its simplicity and effectiveness, especially in social media contexts. It features a pre-trained lexicon containing thousands of words with associated sentiment scores, along with rules and heuristics to handle linguistic nuances and context-specific sentiments. VADER is \"valence aware,\" meaning it considers the valence of words in context to accurately interpret sentiments expressed in text. It assigns sentiment intensity scores, including positive, negative, and neutral scores, as well as a compound score representing the overall sentiment polarity of the text. VADER finds applications in social media analysis, customer feedback analysis, and brand monitoring, providing a robust and efficient solution for sentiment analysis tasks in both research and industry settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82754fbd-d92d-4043-a3b4-1ba90a729106",
   "metadata": {},
   "source": [
    "#### Advantages of VADER for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4dcfbc-2465-46c8-8355-c6105a8b20a1",
   "metadata": {},
   "source": [
    "Designed for Social Media Text: VADER is tailored to analyze sentiment in social media text, which often contains slang, emojis, and informal language. It handles these nuances effectively, making it suitable for platforms like Twitter, Facebook, and online reviews.\n",
    "\n",
    "Rule-Based Approach: VADER employs a rule-based approach that relies on a pre-built lexicon of sentiment words and a set of rules to analyze sentiment. This approach allows VADER to quickly classify text sentiment without the need for extensive training data or complex machine learning models.\n",
    "\n",
    "Valence-Based Scoring: VADER assigns sentiment scores to text based on the valence (positive, negative, or neutral) of individual words and punctuation, as well as special features such as capitalization and degree modifiers. This valence-based scoring captures subtle nuances in sentiment.\n",
    "\n",
    "Handles Emojis and Slangs: VADER is adept at handling emojis, acronyms, slang, and emoticons commonly found in social media text. It interprets these elements in the context of the surrounding text to accurately assess sentiment.\n",
    "\n",
    "Fast and Lightweight: VADER is lightweight and computationally efficient, making it suitable for real-time sentiment analysis applications. It can process large volumes of text quickly, making it ideal for analyzing streams of social media data in real-time.\n",
    "\n",
    "No Training Required: Unlike many machine learning-based sentiment analysis models that require extensive training on labeled data, VADER comes pre-trained with a sentiment lexicon. This eliminates the need for training data and simplifies the deployment process.\n",
    "\n",
    "Interpretable Results: VADER provides interpretable sentiment scores that indicate the intensity of positive, negative, and neutral sentiment in the text. These scores can be easily understood and used to derive insights from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623a1db-be1a-4590-a06d-f83d61b74da6",
   "metadata": {},
   "source": [
    "#### Objective:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ce5032-7962-4a9a-bc88-328fa5d29dd1",
   "metadata": {},
   "source": [
    "The primary objective of this project is to assess the performance of the VADER sentiment analysis tool when applied to both cleaned and uncleaned text data. Additionally, we aim to establish a baseline score for sentiment analysis using VADER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8f4d79-9aad-421e-863c-81ee3264ff24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bb5d18a-562e-4dfa-8aa2-4c08af1a805c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.543, 'pos': 0.457, 'compound': 0.6369}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "text = \"I love this product. It is amaing.\"\n",
    "\n",
    "sentiment_scores = sia.polarity_scores(text)\n",
    "sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2717252b-b83a-4274-bd5b-0b9c418afd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "compound_score = sentiment_scores['compound']\n",
    "\n",
    "if compound_score >= 0.05:\n",
    "    print(\"Positive\")\n",
    "elif compound_score <= -0.05:\n",
    "    print(\"Negative\")\n",
    "else:\n",
    "    print(\"Neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a451230-01c7-44ae-8c0e-c515e3146b7c",
   "metadata": {},
   "source": [
    "### Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb3a053-20cc-4b7a-9a2f-2d9b0fdc3bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss\n",
    "\n",
    "import nltk\n",
    "nltk.data.path.append(\"/path/to/nltk_data\")\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd824d8f-d6ac-444e-93a6-fb8fd835c798",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b4ca2-13e2-4b33-be10-97d77a129932",
   "metadata": {},
   "source": [
    "This dataset comprises 1,600,000 tweets collected using the Twitter API, intended for sentiment analysis purposes. Each tweet is annotated with a polarity label: 0 for negative sentiment, and 4 for positive sentiment. The dataset contains six fields:\n",
    "\n",
    "target: Indicates the polarity of the tweet (0 for negative, 4 for positive).\n",
    "ids: Unique identifier for each tweet.\n",
    "date: Timestamp indicating when the tweet was posted.\n",
    "flag: Query associated with the tweet, if applicable. If there's no query, the value is set to \"NO_QUERY\".\n",
    "user: Username of the user who posted the tweet.\n",
    "text: Actual text content of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f64b8a-dfe7-4dfa-a178-88370f2d9d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"../Desktop/training.1600000.processed.noemoticon.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5818be33-52bc-4aa1-8cfd-857a62ebb33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "585cdbb4-c253-4f03-bf51-8a2583c5f3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>Date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          Date      flag           user  \\\n",
       "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                               text_  \n",
       "0  is upset that he can't update his Facebook by ...  \n",
       "1  @Kenichan I dived many times for the ball. Man...  \n",
       "2    my whole body feels itchy and like its on fire   \n",
       "3  @nationwideclass no, it's not behaving at all....  \n",
       "4                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns = [\"target\", \"ids\", \"Date\", \"flag\", \"user\", \"text_\"]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "954b4594-0197-467e-8d40-61388b9fb9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599999 entries, 0 to 1599998\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1599999 non-null  int64 \n",
      " 1   ids     1599999 non-null  int64 \n",
      " 2   Date    1599999 non-null  object\n",
      " 3   flag    1599999 non-null  object\n",
      " 4   user    1599999 non-null  object\n",
      " 5   text_   1599999 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f23d3d-3bcd-4ac3-9242-8de801998106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599999</td>\n",
       "      <td>1599999</td>\n",
       "      <td>1599999</td>\n",
       "      <td>1599999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>774362</td>\n",
       "      <td>1</td>\n",
       "      <td>659775</td>\n",
       "      <td>1581465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Mon Jun 15 12:53:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lost_dog</td>\n",
       "      <td>isPlayer Has Died! Sorry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>20</td>\n",
       "      <td>1599999</td>\n",
       "      <td>549</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date      flag      user  \\\n",
       "count                        1599999   1599999   1599999   \n",
       "unique                        774362         1    659775   \n",
       "top     Mon Jun 15 12:53:14 PDT 2009  NO_QUERY  lost_dog   \n",
       "freq                              20   1599999       549   \n",
       "\n",
       "                            text_  \n",
       "count                     1599999  \n",
       "unique                    1581465  \n",
       "top     isPlayer Has Died! Sorry   \n",
       "freq                          210  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da133b05-0b17-4712-8b56-91e12e605a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5345bfed-ccc7-4b77-8bc0-033548759213",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['target'] = tweets['target'].replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba5ef9e7-1ffe-416a-9f22-e2dac24b32bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1598314"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['ids'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe48ab6-059c-45b8-b9e5-2d3993991ac0",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56af553-284c-4d5c-b1d1-be8d18b8edbb",
   "metadata": {},
   "source": [
    "Preprocessing the tweets dataset by reducing its size, ensuring data integrity by removing duplicates, and removing unnecessary columns for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "775b7d76-e988-4a27-9db9-73a26d250459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>Date</th>\n",
       "      <th>user</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003313</td>\n",
       "      <td>Tue Jun 16 18:18:13 PDT 2009</td>\n",
       "      <td>DEWGetMeTho77</td>\n",
       "      <td>@Nkluvr4eva My poor little dumpling  In Holmde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998601</td>\n",
       "      <td>Mon Apr 06 23:11:18 PDT 2009</td>\n",
       "      <td>Young_J</td>\n",
       "      <td>I'm off too bed. I gotta wake up hella early t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2300049112</td>\n",
       "      <td>Tue Jun 23 13:40:12 PDT 2009</td>\n",
       "      <td>dougnawoschik</td>\n",
       "      <td>I havent been able to listen to it yet  My spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474319</td>\n",
       "      <td>Mon Jun 01 10:26:09 PDT 2009</td>\n",
       "      <td>thireven</td>\n",
       "      <td>now remembers why solving a relatively big equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2256551006</td>\n",
       "      <td>Sat Jun 20 12:56:51 PDT 2009</td>\n",
       "      <td>taracollins086</td>\n",
       "      <td>Ate too much, feel sick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          Date            user  \\\n",
       "0       0  2200003313  Tue Jun 16 18:18:13 PDT 2009   DEWGetMeTho77   \n",
       "1       0  1467998601  Mon Apr 06 23:11:18 PDT 2009         Young_J   \n",
       "2       0  2300049112  Tue Jun 23 13:40:12 PDT 2009   dougnawoschik   \n",
       "3       0  1993474319  Mon Jun 01 10:26:09 PDT 2009        thireven   \n",
       "4       0  2256551006  Sat Jun 20 12:56:51 PDT 2009  taracollins086   \n",
       "\n",
       "                                               text_  \n",
       "0  @Nkluvr4eva My poor little dumpling  In Holmde...  \n",
       "1  I'm off too bed. I gotta wake up hella early t...  \n",
       "2  I havent been able to listen to it yet  My spe...  \n",
       "3  now remembers why solving a relatively big equ...  \n",
       "4                           Ate too much, feel sick   "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.sample(n=100000, random_state=42)\n",
    "tweets = tweets.drop_duplicates(subset=['ids'])\n",
    "tweets.reset_index(drop=True, inplace=True)\n",
    "\n",
    "column_to_delete = ['flag']\n",
    "tweets = tweets.drop(column_to_delete, axis=1)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde013be-6ccf-4d48-ae77-48f75a6dd4f6",
   "metadata": {},
   "source": [
    "Removing usernames from text: Iterating over each row in the 'text' column and checking if the text starts with a '@' symbol, indicating a mention. If a mention is found, we are removing the mention by finding the index of the first space character after the '@' symbol and retains the text following that space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "160b32be-08ed-4a20-ad94-91cf4d4df8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>Date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003313</td>\n",
       "      <td>Tue Jun 16 18:18:13 PDT 2009</td>\n",
       "      <td>DEWGetMeTho77</td>\n",
       "      <td>My poor little dumpling  In Holmdel vids he wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998601</td>\n",
       "      <td>Mon Apr 06 23:11:18 PDT 2009</td>\n",
       "      <td>Young_J</td>\n",
       "      <td>I'm off too bed. I gotta wake up hella early t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2300049112</td>\n",
       "      <td>Tue Jun 23 13:40:12 PDT 2009</td>\n",
       "      <td>dougnawoschik</td>\n",
       "      <td>I havent been able to listen to it yet  My spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474319</td>\n",
       "      <td>Mon Jun 01 10:26:09 PDT 2009</td>\n",
       "      <td>thireven</td>\n",
       "      <td>now remembers why solving a relatively big equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2256551006</td>\n",
       "      <td>Sat Jun 20 12:56:51 PDT 2009</td>\n",
       "      <td>taracollins086</td>\n",
       "      <td>Ate too much, feel sick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          Date            user  \\\n",
       "0       0  2200003313  Tue Jun 16 18:18:13 PDT 2009   DEWGetMeTho77   \n",
       "1       0  1467998601  Mon Apr 06 23:11:18 PDT 2009         Young_J   \n",
       "2       0  2300049112  Tue Jun 23 13:40:12 PDT 2009   dougnawoschik   \n",
       "3       0  1993474319  Mon Jun 01 10:26:09 PDT 2009        thireven   \n",
       "4       0  2256551006  Sat Jun 20 12:56:51 PDT 2009  taracollins086   \n",
       "\n",
       "                                                text  \n",
       "0  My poor little dumpling  In Holmdel vids he wa...  \n",
       "1  I'm off too bed. I gotta wake up hella early t...  \n",
       "2  I havent been able to listen to it yet  My spe...  \n",
       "3  now remembers why solving a relatively big equ...  \n",
       "4                           Ate too much, feel sick   "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['text'] = tweets['text_']\n",
    "\n",
    "for i in range(len(tweets['text'])):\n",
    "    str_val = tweets['text'].iloc[i]\n",
    "    if str_val.startswith(\"@\"):\n",
    "        first_idx = str_val.index(\" \") + 1\n",
    "        tweets.loc[i, 'text'] = str_val[first_idx:]\n",
    "\n",
    "tweets.drop(columns=['text_'], inplace=True)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe70208-699a-4bf1-9795-06ad14b8852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tweets.Date:\n",
    "    l = len(tweets.Date.iloc[0])\n",
    "    if ((len(i)!=l) and (i[3]!=\" \") and (i[7]!=\" \") and (i[0]!=\" \") and (i[19]!=\" \") and (i[23]!=\" \")):\n",
    "        print(i, \"inconsistent\")\n",
    "        break;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d1d55b-b4b9-4a23-83a9-caf1cd9d9e95",
   "metadata": {},
   "source": [
    "Handling Date column: Extracting date components from the 'Date' column, combining them into a datetime format, and dropping the original date components columns, resulting in a DataFrame with the desired datetime information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4d2811a-314c-41b2-95dc-c1e2e051afed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003313</td>\n",
       "      <td>DEWGetMeTho77</td>\n",
       "      <td>My poor little dumpling  In Holmdel vids he wa...</td>\n",
       "      <td>2009-06-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998601</td>\n",
       "      <td>Young_J</td>\n",
       "      <td>I'm off too bed. I gotta wake up hella early t...</td>\n",
       "      <td>2009-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2300049112</td>\n",
       "      <td>dougnawoschik</td>\n",
       "      <td>I havent been able to listen to it yet  My spe...</td>\n",
       "      <td>2009-06-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474319</td>\n",
       "      <td>thireven</td>\n",
       "      <td>now remembers why solving a relatively big equ...</td>\n",
       "      <td>2009-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2256551006</td>\n",
       "      <td>taracollins086</td>\n",
       "      <td>Ate too much, feel sick</td>\n",
       "      <td>2009-06-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids            user  \\\n",
       "0       0  2200003313   DEWGetMeTho77   \n",
       "1       0  1467998601         Young_J   \n",
       "2       0  2300049112   dougnawoschik   \n",
       "3       0  1993474319        thireven   \n",
       "4       0  2256551006  taracollins086   \n",
       "\n",
       "                                                text  date_time  \n",
       "0  My poor little dumpling  In Holmdel vids he wa... 2009-06-16  \n",
       "1  I'm off too bed. I gotta wake up hella early t... 2009-04-06  \n",
       "2  I havent been able to listen to it yet  My spe... 2009-06-23  \n",
       "3  now remembers why solving a relatively big equ... 2009-06-01  \n",
       "4                           Ate too much, feel sick  2009-06-20  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['day'] = tweets['Date'].str.split().str[0]\n",
    "tweets['month'] = tweets['Date'].str.split().str[1]\n",
    "tweets['date'] = tweets['Date'].str.split().str[2]\n",
    "tweets['year'] = tweets['Date'].str.split().str[-1]\n",
    "\n",
    "tweets['date_time'] = tweets['day'] + ' ' + tweets['month'] + ' ' + tweets['date'] + ' ' + tweets['year']\n",
    "tweets['date_time'] = pd.to_datetime(tweets['date_time'], format='%a %b %d %Y')\n",
    "\n",
    "tweets.drop(columns=['day', 'month', 'date', 'year', 'Date'], inplace=True)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f5250-d602-4d74-8114-4ee821ede117",
   "metadata": {},
   "source": [
    "### NLTK Text Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc650b-1d0f-4180-86ef-30d54f30bc6b",
   "metadata": {},
   "source": [
    "This demonstrates a text cleaning pipeline using NLTK (Natural Language Toolkit) in Python. It consists of a function clean_text() that preprocesses input text by removing special characters and digits, tokenizing the text, removing stopwords, and lemmatizing the tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846778f8-53c7-400f-b6b8-5bc4d1254cb3",
   "metadata": {},
   "source": [
    "### clean_text\n",
    "\n",
    "This function takes a single argument text, representing the input text to be cleaned.\n",
    "\n",
    "Special Character and Digit Removal:\n",
    "\n",
    "Removes special characters and digits from the input text, retaining only alphabetic characters and whitespace.\n",
    "\n",
    "Tokenization:\n",
    "\n",
    "Splits the cleaned text into individual words or tokens using NLTK's word_tokenize() function.\n",
    "\n",
    "Lowercasing:\n",
    "\n",
    "Converts all tokens to lowercase to ensure uniformity.\n",
    "\n",
    "Stopword Removal:\n",
    "\n",
    "Removes common stopwords (e.g., 'and', 'the', 'is') from the tokenized text using NLTK's English stopwords corpus.\n",
    "\n",
    "Lemmatization:\n",
    "\n",
    "Lemmatizes the remaining tokens, converting them to their base or dictionary form, using NLTK's WordNetLemmatizer.\n",
    "\n",
    "Joining Tokens:\n",
    "\n",
    "Joins the lemmatized tokens back into a single string, separated by whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c693ae19-78b0-4a16-bf56-fe094b01cff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1d53f6d-9d08-4efc-ae92-292d48b92f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Join tokens back into a string\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff55b341-a58e-4f0d-888c-9fe56e1d3cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>date_time</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003313</td>\n",
       "      <td>DEWGetMeTho77</td>\n",
       "      <td>My poor little dumpling  In Holmdel vids he wa...</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>poor little dumpling holmdel vids really tryin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998601</td>\n",
       "      <td>Young_J</td>\n",
       "      <td>I'm off too bed. I gotta wake up hella early t...</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>im bed got ta wake hella early tomorrow morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2300049112</td>\n",
       "      <td>dougnawoschik</td>\n",
       "      <td>I havent been able to listen to it yet  My spe...</td>\n",
       "      <td>2009-06-23</td>\n",
       "      <td>havent able listen yet speaker busted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474319</td>\n",
       "      <td>thireven</td>\n",
       "      <td>now remembers why solving a relatively big equ...</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>remembers solving relatively big equation two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2256551006</td>\n",
       "      <td>taracollins086</td>\n",
       "      <td>Ate too much, feel sick</td>\n",
       "      <td>2009-06-20</td>\n",
       "      <td>ate much feel sick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids            user  \\\n",
       "0       0  2200003313   DEWGetMeTho77   \n",
       "1       0  1467998601         Young_J   \n",
       "2       0  2300049112   dougnawoschik   \n",
       "3       0  1993474319        thireven   \n",
       "4       0  2256551006  taracollins086   \n",
       "\n",
       "                                                text  date_time  \\\n",
       "0  My poor little dumpling  In Holmdel vids he wa... 2009-06-16   \n",
       "1  I'm off too bed. I gotta wake up hella early t... 2009-04-06   \n",
       "2  I havent been able to listen to it yet  My spe... 2009-06-23   \n",
       "3  now remembers why solving a relatively big equ... 2009-06-01   \n",
       "4                           Ate too much, feel sick  2009-06-20   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  poor little dumpling holmdel vids really tryin...  \n",
       "1    im bed got ta wake hella early tomorrow morning  \n",
       "2              havent able listen yet speaker busted  \n",
       "3  remembers solving relatively big equation two ...  \n",
       "4                                 ate much feel sick  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['cleaned_text'] = tweets['text']\n",
    "\n",
    "for i in range(len(tweets['cleaned_text'])):\n",
    "    str = tweets['cleaned_text'].iloc[i]\n",
    "    tweets.loc[i, 'cleaned_text'] = clean_text(str)\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bcb85e-bacb-44bd-a195-76ca949c48a3",
   "metadata": {},
   "source": [
    "### Sentiment Score Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d76cc89-8353-4daa-848a-bb683f48b6d6",
   "metadata": {},
   "source": [
    "Sentiment Score Computation Loop: The function iterates over each entry in the specified column of the tweets DataFrame using a for loop. For each entry, it retrieves the text (t) from the specified column. It computes the sentiment scores for the text using the polarity_scores() method of the SentimentIntensityAnalyzer object (sia) and stores the scores in the respective arrays (neg, neu, pos, compound). This is done for both cleaned and uncleaned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c20bf690-3648-467b-bc81-9d9d5fa5671b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>date_time</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>text_neg</th>\n",
       "      <th>text_neu</th>\n",
       "      <th>text_pos</th>\n",
       "      <th>text_compound</th>\n",
       "      <th>cleaned_text_neg</th>\n",
       "      <th>cleaned_text_neu</th>\n",
       "      <th>cleaned_text_pos</th>\n",
       "      <th>cleaned_text_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2200003313</td>\n",
       "      <td>DEWGetMeTho77</td>\n",
       "      <td>My poor little dumpling  In Holmdel vids he wa...</td>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>poor little dumpling holmdel vids really tryin...</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.117</td>\n",
       "      <td>-0.4013</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.4013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467998601</td>\n",
       "      <td>Young_J</td>\n",
       "      <td>I'm off too bed. I gotta wake up hella early t...</td>\n",
       "      <td>2009-04-06</td>\n",
       "      <td>im bed got ta wake hella early tomorrow morning</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2300049112</td>\n",
       "      <td>dougnawoschik</td>\n",
       "      <td>I havent been able to listen to it yet  My spe...</td>\n",
       "      <td>2009-06-23</td>\n",
       "      <td>havent able listen yet speaker busted</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1993474319</td>\n",
       "      <td>thireven</td>\n",
       "      <td>now remembers why solving a relatively big equ...</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>remembers solving relatively big equation two ...</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.2263</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2256551006</td>\n",
       "      <td>taracollins086</td>\n",
       "      <td>Ate too much, feel sick</td>\n",
       "      <td>2009-06-20</td>\n",
       "      <td>ate much feel sick</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids            user  \\\n",
       "0       0  2200003313   DEWGetMeTho77   \n",
       "1       0  1467998601         Young_J   \n",
       "2       0  2300049112   dougnawoschik   \n",
       "3       0  1993474319        thireven   \n",
       "4       0  2256551006  taracollins086   \n",
       "\n",
       "                                                text  date_time  \\\n",
       "0  My poor little dumpling  In Holmdel vids he wa... 2009-06-16   \n",
       "1  I'm off too bed. I gotta wake up hella early t... 2009-04-06   \n",
       "2  I havent been able to listen to it yet  My spe... 2009-06-23   \n",
       "3  now remembers why solving a relatively big equ... 2009-06-01   \n",
       "4                           Ate too much, feel sick  2009-06-20   \n",
       "\n",
       "                                        cleaned_text  text_neg  text_neu  \\\n",
       "0  poor little dumpling holmdel vids really tryin...     0.151     0.732   \n",
       "1    im bed got ta wake hella early tomorrow morning     0.000     1.000   \n",
       "2              havent able listen yet speaker busted     0.000     1.000   \n",
       "3  remembers solving relatively big equation two ...     0.168     0.711   \n",
       "4                                 ate much feel sick     0.452     0.548   \n",
       "\n",
       "   text_pos  text_compound  cleaned_text_neg  cleaned_text_neu  \\\n",
       "0     0.117        -0.4013             0.214             0.621   \n",
       "1     0.000         0.0000             0.000             1.000   \n",
       "2     0.000         0.0000             0.000             1.000   \n",
       "3     0.122        -0.2263             0.241             0.584   \n",
       "4     0.000        -0.5106             0.524             0.476   \n",
       "\n",
       "   cleaned_text_pos  cleaned_text_compound  \n",
       "0             0.166                -0.4013  \n",
       "1             0.000                 0.0000  \n",
       "2             0.000                 0.0000  \n",
       "3             0.175                -0.2263  \n",
       "4             0.000                -0.5106  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sent_scores(col):\n",
    "    \n",
    "    length = len(tweets[col])\n",
    "    neg = np.empty([1, length])\n",
    "    neg = neg[0]\n",
    "    neu = np.empty([1, length])\n",
    "    neu = neu[0]\n",
    "    pos = np.empty([1, length])\n",
    "    pos = pos[0]\n",
    "    compound = np.empty([1, length])\n",
    "    compound = compound[0]\n",
    "\n",
    "    for i in range(length):\n",
    "        t = tweets[col][i]\n",
    "        sentiment_scores = sia.polarity_scores(t)\n",
    "        neg[i] = sentiment_scores[\"neg\"]\n",
    "        neu[i] = sentiment_scores[\"neu\"]\n",
    "        pos[i] = sentiment_scores[\"pos\"]\n",
    "        compound[i] = sentiment_scores[\"compound\"]\n",
    "\n",
    "    tweets[col+\"_neg\"] = neg\n",
    "    tweets[col+\"_neu\"] = neu\n",
    "    tweets[col+\"_pos\"] = pos\n",
    "    tweets[col+\"_compound\"] = compound\n",
    "\n",
    "sent_scores(\"text\")\n",
    "sent_scores(\"cleaned_text\")\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d0070c3-01f5-440e-8cc1-cd8b1a585f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value in text_compound: -0.9776\n",
      "Maximum value in text_compound: 0.9928\n"
     ]
    }
   ],
   "source": [
    "min_value = tweets['text_compound'].min()\n",
    "max_value = tweets['text_compound'].max()\n",
    "\n",
    "print(\"Minimum value in text_compound:\", min_value)\n",
    "print(\"Maximum value in text_compound:\", max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d4ef1c-0fb5-463c-bf46-a698e59e9f7f",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f337c97-a6bf-4a9f-83c9-03e745c0623a",
   "metadata": {},
   "source": [
    "The compound score, a 'normalized, weighted composite score,' is derived by summing the valence scores of each word in the lexicon, adjusted based on specific rules, and then normalized to fall within the range of -1 (most extreme negative) to +1 (most extreme positive). This metric serves as a valuable single-dimensional measure of sentiment for a given sentence. Typical threshold values are as follows:\n",
    "\n",
    "Positive sentiment: Compound score ≥ 0.05\n",
    "\n",
    "Neutral sentiment: -0.05 < Compound score < 0.05\n",
    "\n",
    "Negative sentiment: Compound score ≤ -0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2969d283-48bc-47f1-a34f-361fedb66135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================= text_compound =============================\n",
      "ROC-AUC score: 0.7203910652774609\n",
      "Accuracy: 0.7190791017377262\n",
      "Recall: 0.8616289113655995\n",
      "============================= cleaned_text_compound =============================\n",
      "ROC-AUC score: 0.7024576236263737\n",
      "Accuracy: 0.7025906439437264\n",
      "Recall: 0.8686\n"
     ]
    }
   ],
   "source": [
    "def evaluate(col):\n",
    "    \n",
    "    tweets['predicted_sentiment'] = tweets[col].apply(lambda x: 1 if x >= 0.05 else (0 if x <= -0.05 else None))\n",
    "    \n",
    "    # remove rows with neutral sentiment (nans)\n",
    "    tweets.dropna(subset=['predicted_sentiment'], inplace=True)\n",
    "\n",
    "    accuracy = accuracy_score(tweets['target'], tweets['predicted_sentiment'])\n",
    "    precision = precision_score(tweets['target'], tweets['predicted_sentiment'])\n",
    "    recall = recall_score(tweets['target'], tweets['predicted_sentiment'])\n",
    "    f1 = f1_score(tweets['target'], tweets['predicted_sentiment'])\n",
    "    roc_auc = roc_auc_score(tweets['target'], tweets['predicted_sentiment'])\n",
    "    \n",
    "    print(\"============================= \"+col+\" =============================\")\n",
    "    print(\"ROC-AUC score:\", roc_auc)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Recall:\", recall)\n",
    "    \n",
    "evaluate('text_compound')\n",
    "evaluate('cleaned_text_compound')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e34cd-729d-4262-9e08-55d0f1a7ef16",
   "metadata": {},
   "source": [
    "While a ROC-AUC score of 0.7204 can serve as a reasonable starting point for sentiment analysis tasks, it's essential to consider various factors to determine its adequacy as a baseline. Additionally, continuous experimentation and refinement of models are often necessary to improve performance further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b68d5-d41c-4ecf-a03b-a995759579da",
   "metadata": {},
   "source": [
    "### Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a961d5-c623-4d64-b2d0-2159617eef1b",
   "metadata": {},
   "source": [
    "Through this project, we have documented the observation that VADER performs better with uncleaned text data compared to cleaned text data. This notebook serves as a valuable resource for researchers, practitioners, and enthusiasts in the field of sentiment analysis, offering insights into the nuances of text preprocessing and its impact on sentiment analysis tool performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e5fdb-2e0d-4c8a-81de-3b709433f6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64efa357-5b03-4f84-b6e0-d0a93d41f310",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
